{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy, requests\n",
    "from scrapy.http import TextResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 뉴스 기사 검색 키워드 : \"코로나 백신\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://search.naver.com/search.naver?where=news&query=코로나%20백신&pd=4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EB%B0%B1%EC%8B%A0&pd=4>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36 Edg/88.0.705.68'}\n",
    "req = requests.get(URL, headers=headers)\n",
    "response = TextResponse(req.url, body=req.text, encoding='utf-8')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['문대통령 \"어떤 백신이든 정부가 안전성 책임진다\"',\n",
       " '울릉군 AZ 백신 접종 시작… 요양시설 종사자 11명',\n",
       " '\"국민 54%, 코로나19 백신 접종은 모두의 책임\"',\n",
       " '어제 백신 이상반응 4건 신고, 누적 156건',\n",
       " '프·독 “AZ백신 고령층에도 효능”…정부, 접종여부 결정 빨라지나',\n",
       " '코로나19 백신 어제 1,442명 접종…나흘동안 총 2만 3,086명',\n",
       " '백신 접종후 경미한 이상반응 156건…“3일 내 완치”',\n",
       " '한국도 ‘백신 여권’ 도입 나선다',\n",
       " '\"코로나 백신, 매년 접종받아야 할 가능성 낮아\"',\n",
       " \"경남도, 코로나19 백신 접종 '순조'(종합)\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '코로나 백신' 키워드 함수 설정\n",
    "\n",
    "def title_vac():\n",
    "    URL = \"https://search.naver.com/search.naver?where=news&query=코로나%20백신&sm=tab_opt&sort=0&photo=0&field=0&reporter_article=&pd=4&ds=&de=&docid=&nso=so%3Ar%2Cp%3A1d%2Ca%3Aall&mynews=0&refresh_start=0&related=0\"\n",
    "    # URL = \"https://search.naver.com/search.naver?where=news&query=코로나%20백신&pd=4&ds=&de=\"\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36 Edg/88.0.705.68'}\n",
    "    req = requests.get(URL, headers=headers)\n",
    "    response = TextResponse(req.url, body=req.text, encoding='utf-8')\n",
    "    title = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['문대통령 \"어떤 백신이든 정부가 안전성 책임진다\"',\n",
       " '울릉군 AZ 백신 접종 시작… 요양시설 종사자 11명',\n",
       " '\"국민 54%, 코로나19 백신 접종은 모두의 책임\"',\n",
       " '어제 백신 이상반응 4건 신고, 누적 156건',\n",
       " '프·독 “AZ백신 고령층에도 효능”…정부, 접종여부 결정 빨라지나',\n",
       " '코로나19 백신 어제 1,442명 접종…나흘동안 총 2만 3,086명',\n",
       " '백신 접종후 경미한 이상반응 156건…“3일 내 완치”',\n",
       " '한국도 ‘백신 여권’ 도입 나선다',\n",
       " '\"코로나 백신, 매년 접종받아야 할 가능성 낮아\"',\n",
       " \"경남도, 코로나19 백신 접종 '순조'(종합)\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_vac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%82%AC%ED%9A%8C%EC%A0%81%EA%B1%B0%EB%A6%AC%EB%91%90%EA%B8%B0&pd=4>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해당 기사 링크 추가(기사제목, 해당기사 링크 순으로 정렬)\n",
    "URL = \"https://search.naver.com/search.naver?where=news&query=코로나%20사회적거리두기&pd=4\"\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36 Edg/88.0.705.68'}\n",
    "req = requests.get(URL, headers=headers)\n",
    "response = TextResponse(req.url, body=req.text, encoding='utf-8')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " 10,\n",
       " [('1월 생산 8개월 만에 감소…거리두기에도 소비 1.6%↑(종합2보)',\n",
       "   'http://www.newsis.com/view/?id=NISX20210226_0001352545&cID=10401&pID=10400'),\n",
       "  ('오늘 코로나 2년차 새학년 첫등교…유·초1∼2·고3 매일 학교에',\n",
       "   'http://yna.kr/AKR20210226096500530?did=1195m'),\n",
       "  ('영광군, 14일까지 ‘사회적 거리두기’ 1.5단계 연장',\n",
       "   'https://view.asiae.co.kr/article/2021030212551647935')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "pairs = [pair for pair in zip(titles, links)]\n",
    "len(titles), len(links), pairs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 뉴스 기사 검색 키워드 : \"코로나 사회적거리두기\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%82%AC%ED%9A%8C%EC%A0%81%EA%B1%B0%EB%A6%AC%EB%91%90%EA%B8%B0&pd=4>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = \"https://search.naver.com/search.naver?where=news&query=코로나%20사회적거리두기&pd=4\"\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36 Edg/88.0.705.68'}\n",
    "req = requests.get(URL, headers=headers)\n",
    "response = TextResponse(req.url, body=req.text, encoding='utf-8')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " 10,\n",
       " [('1월 생산 8개월 만에 감소…거리두기에도 소비 1.6%↑(종합2보)',\n",
       "   'http://www.newsis.com/view/?id=NISX20210226_0001352545&cID=10401&pID=10400'),\n",
       "  ('오늘 코로나 2년차 새학년 첫등교…유·초1∼2·고3 매일 학교에',\n",
       "   'http://yna.kr/AKR20210226096500530?did=1195m'),\n",
       "  ('영광군, 14일까지 ‘사회적 거리두기’ 1.5단계 연장',\n",
       "   'https://view.asiae.co.kr/article/2021030212551647935')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "pairs = [pair for pair in zip(titles, links)]\n",
    "len(titles), len(links), pairs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 뉴스 기사 검색 키워드 : \"코로나 확진\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%88%98%EB%8F%84%EA%B6%8C%20%ED%99%95%EC%A7%84&pd=4>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = \"https://search.naver.com/search.naver?where=news&query=코로나%20수도권%20확진&pd=4\"\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36 Edg/88.0.705.68'}\n",
    "req = requests.get(URL, headers=headers)\n",
    "response = TextResponse(req.url, body=req.text, encoding='utf-8')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['코로나 확진자 424명…이틀 연속 400명대(상보)',\n",
       "  '신규확진 424명 이틀째 400명대…백신접종 1주일째, 속도 박차(종합)',\n",
       "  '日 코로나 신규 확진 다시 1천 명대…수도권 긴급사태 재연장',\n",
       "  '코로나19 신규 확진 424명…이틀 연속 400명대',\n",
       "  '[속보] 코로나19 신규 확진자 424명...이틀째 400명대',\n",
       "  '코로나 신규 확진자 424명…‘백신 접종’ 누적 15만4천명',\n",
       "  \"신규 확진 424명…8일째 1주 일평균 300명대 '요지부동'(상보)\",\n",
       "  \"'코로나19' 신규확진 424명…지역발생 401명\",\n",
       "  '대구서 코로나19 신규확진자 20명 발생…대학생 모임 관련 누적 28명',\n",
       "  '코로나19 신규확진 424명'],\n",
       " ['https://view.asiae.co.kr/article/2021030409501160278',\n",
       "  'http://yna.kr/AKR20210304033051530?did=1195m',\n",
       "  'http://www.munhwa.com/news/view.html?no=20210304MW072016547576',\n",
       "  'https://imnews.imbc.com/news/2021/society/article/6108154_34873.html',\n",
       "  'http://news.khan.co.kr/kh_news/khan_art_view.html?artid=202103040935001&code=940100',\n",
       "  'http://www.hani.co.kr/arti/society/health/985342.html',\n",
       "  'https://www.news1.kr/articles/?4229866',\n",
       "  'http://www.joseilbo.com/news/news_read.php?uid=418341&class=33&grp=',\n",
       "  'http://www.kyongbuk.co.kr/news/articleView.html?idxno=2070058',\n",
       "  'http://sports.khan.co.kr/news/sk_index.html?art_id=202103040950003&sec_id=560101&pt=nv']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract(),\n",
    "          response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()]\n",
    "links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "pairs = [pair for pair in zip(titles, links)]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프로젝트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf covid_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'covid_keyword', using template directory '/home/ubuntu/.pyenv/versions/3.6.9/envs/python3/lib/python3.6/site-packages/scrapy/templates/project', created in:\r\n",
      "    /home/ubuntu/python3/project/covid_keyword\r\n",
      "\r\n",
      "You can start your first spider with:\r\n",
      "    cd covid_keyword\r\n",
      "    scrapy genspider example example.com\r\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject covid_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mcovid_keyword\u001b[00m\r\n",
      "├── \u001b[01;34mcovid_keyword\u001b[00m\r\n",
      "│   ├── __init__.py\r\n",
      "│   ├── items.py\r\n",
      "│   ├── middlewares.py\r\n",
      "│   ├── pipelines.py\r\n",
      "│   ├── settings.py\r\n",
      "│   └── \u001b[01;34mspiders\u001b[00m\r\n",
      "│       └── __init__.py\r\n",
      "└── scrapy.cfg\r\n",
      "\r\n",
      "2 directories, 7 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree covid_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_keyword/covid_keyword/items.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile covid_keyword/covid_keyword/items.py\n",
    "# import scrapy\n",
    "\n",
    "\n",
    "# class CovidKeywordItem(scrapy.Item):\n",
    "#     title = scrapy.Field()\n",
    "#     link = scrapy.Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_keyword/covid_keyword/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile covid_keyword/covid_keyword/spiders/spider.py\n",
    "\n",
    "# import scrapy\n",
    "# from covid_keyword.items import CovidKeywordItem\n",
    "\n",
    "# class CovidSpider(scrapy.Spider):\n",
    "#     name = \"CovidKeyword\"\n",
    "#     allow_domain = ['https://www.naver.com/']\n",
    "#     start_urls = [\"https://search.naver.com/search.naver?where=news&query=&pd=4\"]\n",
    "    \n",
    "#     def __init__(self, kword1='국내',kword2='백신', **kwargs):\n",
    "#         self.start_url = f\"https://search.naver.com/search.naver?where=news&query=코로나%20{kword1}%20{kword2}&pd=4&ds=&de=\"\n",
    "#         super().__init__(**kwargs)\n",
    "        \n",
    "#     def start_requests(self):\n",
    "#         url = self.start_url\n",
    "#         yield scrapy.Request(url, callback=self.parse)\n",
    "        \n",
    "#     def parse(self, response):\n",
    "#         item = CovidKeywordItem() \n",
    "#         titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['title'] = [title for title in titles]\n",
    "#         item['link'] = [link for link in links]\n",
    "#         yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_keyword/covid_keyword/items.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_keyword/covid_keyword/items.py\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class CovidKeywordItem(scrapy.Item):\n",
    "    vaccine = scrapy.Field()\n",
    "    infection = scrapy.Field()\n",
    "    soc_distance = scrapy.Field()\n",
    "    support = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_keyword/covid_keyword/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_keyword/covid_keyword/spiders/spider.py\n",
    "\n",
    "import scrapy\n",
    "from covid_keyword.items import CovidKeywordItem\n",
    "\n",
    "class CovidSpider(scrapy.Spider):\n",
    "    name = 'CovidKeyword'\n",
    "    allow_domain = ['https://www.naver.com/']\n",
    "\n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(\"https://search.naver.com/search.naver?where=news&query=코로나%20국내%20백신&pd=4\", callback=self.parse_kword1)\n",
    "        yield scrapy.Request(\"https://search.naver.com/search.naver?where=news&query=코로나%20수도권%20확진&pd=4\", callback=self.parse_kword2)\n",
    "        yield scrapy.Request(\"https://search.naver.com/search.naver?where=news&query=코로나%20사회적거리두기&pd=4\", callback=self.parse_kword3)\n",
    "        yield scrapy.Request(\"https://search.naver.com/search.naver?where=news&query=코로나%20정부%20재난지원금&pd=4\", callback=self.parse_kword4)\n",
    "            \n",
    "    def parse_kword1(self, response):\n",
    "        item = CovidKeywordItem()\n",
    "        vaccine_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "        vaccine_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "        item['vaccine'] = [vaccine for vaccine in zip(vaccine_titles, vaccine_links)][:3]\n",
    "        yield item\n",
    "                \n",
    "    def parse_kword2(self, response):\n",
    "        item = CovidKeywordItem()\n",
    "        infection_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "        infection_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "        item['infection'] = [infection for infection in zip(infection_titles, infection_links)][:3]\n",
    "        yield item\n",
    "\n",
    "    def parse_kword3(self, response):\n",
    "        item = CovidKeywordItem()\n",
    "        soc_distance_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "        soc_distance_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "        item['soc_distance'] = [soc_distance for soc_distance in zip(soc_distance_titles, soc_distance_links)][:3]\n",
    "        yield item\n",
    "\n",
    "    def parse_kword4(self, response):\n",
    "        item = CovidKeywordItem()\n",
    "        support_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "        support_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "        item['support'] = [support for support in zip(support_titles, support_links)][:3]        \n",
    "        yield item\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_keyword/covid_keyword/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile covid_keyword/covid_keyword/spiders/spider.py\n",
    "\n",
    "# import scrapy\n",
    "# from covid_keyword.items import CovidKeywordItem\n",
    "\n",
    "# class CovidSpider(scrapy.Spider):\n",
    "#     name = 'CovidKeyword'\n",
    "#     allow_domain = ['https://www.naver.com/']\n",
    "#     start_urls = [\"https://search.naver.com/search.naver?where=news&query=코로나%20수도권%20확진&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20국내%20백신&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20사회적거리두기&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20정부%20재난지원금&pd=4\",\n",
    "#                  ]\n",
    "        \n",
    "#     def start_requests(self):\n",
    "#         urls = self.start_urls                            \n",
    "#         for url in urls:\n",
    "#             yield scrapy.Request(url, callback=self.parse_kword1)\n",
    "            \n",
    "#     def parse_kword1(self, response):\n",
    "#         vaccine_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         vaccine_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['vaccine'] = [vaccine for vaccine in zip(vaccine_titles, vaccine_links)]\n",
    "#         yield scrapy.Request(url, callback=self.parse_kword2)\n",
    "                \n",
    "#     def parse_kword2(self, response):\n",
    "#         infection_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         infection_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['infection'] = [infection for infection in zip(infection_titles, infection_links)]\n",
    "#         yield scrapy.Request(url, callback=self.parse_kword3)\n",
    "\n",
    "#     def parse_kword3(self, response):\n",
    "#         soc_distance_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         soc_distance_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['soc_distance'] = [soc_distance for soc_distance in zip(soc_distance_titles, soc_distance_links)]\n",
    "#         yield scrapy.Request(url, callback=self.parse_kword4)\n",
    "\n",
    "#     def parse_kword4(self, response):\n",
    "#         item = CovidKeywordItem()\n",
    "#         support_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         support_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['vaccine']\n",
    "#         item['infection']\n",
    "#         item['soc_distance']\n",
    "#         item['support'] = [support for support in zip(support_titles, support_links)]        \n",
    "#         yield item\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_keyword/covid_keyword/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile covid_keyword/covid_keyword/spiders/spider.py\n",
    "\n",
    "# import scrapy\n",
    "# from covid_keyword.items import CovidKeywordItem\n",
    "\n",
    "# class CovidSpider(scrapy.Spider):\n",
    "#     name = 'CovidKeyword'\n",
    "#     allow_domain = ['https://www.naver.com/']\n",
    "#     start_urls = [\"https://search.naver.com/search.naver?where=news&query=코로나%20수도권%20확진&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20국내%20백신&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20사회적거리두기&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20정부%20재난지원금&pd=4\",\n",
    "#                  ]\n",
    "        \n",
    "#     def start_requests(self):\n",
    "#         urls = self.start_urls                            \n",
    "#         for url in urls:\n",
    "#             yield scrapy.Request(url, callback=self.parse_kword1)\n",
    "            \n",
    "#     def parse_kword1(self, response):\n",
    "#         vaccine_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         vaccine_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['vaccine'] = [vaccine for vaccine in zip(vaccine_titles, vaccine_links)]\n",
    "#         yield scrapy.Request(url, callback=self.parse_kword2)\n",
    "                \n",
    "#     def parse_kword2(self, response):\n",
    "#         infection_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         infection_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['infection'] = [infection for infection in zip(infection_titles, infection_links)]\n",
    "#         yield scrapy.Request(url, callback=self.parse_kword3)\n",
    "\n",
    "#     def parse_kword3(self, response):\n",
    "#         soc_distance_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         soc_distance_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['soc_distance'] = [soc_distance for soc_distance in zip(soc_distance_titles, soc_distance_links)]\n",
    "#         yield scrapy.Request(url, callback=self.parse_kword4)\n",
    "\n",
    "#     def parse_kword4(self, response):\n",
    "#         item = CovidKeywordItem()\n",
    "#         support_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         support_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['support'] = [support for support in zip(support_titles, support_links)]\n",
    "#         yield item\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_keyword/covid_keyword/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile covid_keyword/covid_keyword/spiders/spider.py\n",
    "\n",
    "# import scrapy\n",
    "# from covid_keyword.items import CovidKeywordItem\n",
    "\n",
    "# class CovidSpider(scrapy.Spider):\n",
    "#     name = 'CovidKeyword'\n",
    "#     allow_domain = ['https://www.naver.com/']\n",
    "# #        \n",
    "#     def start_requests(self):\n",
    "#         url = \"https://search.naver.com/search.naver?where=news&query=코로나%20국내%20백신&pd=4\"                           \n",
    "#         yield scrapy.Request(url, callback=self.parse_kword1)\n",
    "            \n",
    "#     def parse_kword1(self, response):\n",
    "#         item = CovidKeywordItem()\n",
    "#         vaccine_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         vaccine_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['vaccine'] = [vaccine for vaccine in zip(vaccine_titles, vaccine_links)]\n",
    "#         yield item\n",
    "# #\n",
    "#     def start_requests(self):\n",
    "#         url = \"https://search.naver.com/search.naver?where=news&query=코로나%20국내%20확진&pd=4\"                           \n",
    "#         yield scrapy.Request(url, callback=self.parse_kword2)\n",
    "                \n",
    "#     def parse_kword2(self, response):\n",
    "#         item = CovidKeywordItem()\n",
    "#         infection_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         infection_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['infection'] = [infection for infection in zip(infection_titles, infection_links)]\n",
    "#         yield item\n",
    "# #\n",
    "#     def start_requests(self):\n",
    "#         url = \"https://search.naver.com/search.naver?where=news&query=코로나%20사회적거리두기&pd=4\"                           \n",
    "#         yield scrapy.Request(url, callback=self.parse_kword3)\n",
    "\n",
    "#     def parse_kword3(self, response):\n",
    "#         item = CovidKeywordItem()\n",
    "#         soc_distance_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         soc_distance_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['soc_distance'] = [soc_distance for soc_distance in zip(soc_distance_titles, soc_distance_links)]\n",
    "#         yield item\n",
    "# #\n",
    "#     def start_requests(self):\n",
    "#         url = \"https://search.naver.com/search.naver?where=news&query=코로나%20재난지원금&pd=4\"                           \n",
    "#         yield scrapy.Request(url, callback=self.parse_kword4)\n",
    "\n",
    "#     def parse_kword4(self, response):\n",
    "#         item = CovidKeywordItem()\n",
    "#         support_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         support_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['support'] = [support for support in zip(support_titles, support_links)]\n",
    "#         yield item\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_keyword/covid_keyword/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile covid_keyword/covid_keyword/spiders/spider.py\n",
    "\n",
    "# import scrapy\n",
    "# from covid_keyword.items import CovidKeywordItem\n",
    "\n",
    "# class CovidSpider(scrapy.Spider):\n",
    "#     name = 'CovidKeyword'\n",
    "#     allow_domain = ['https://www.naver.com/']\n",
    "#     start_urls = [\"https://search.naver.com/search.naver?where=news&query=코로나%20수도권%20확진&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20국내%20백신&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20사회적거리두기&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20정부%20재난지원금&pd=4\",\n",
    "#                  ]\n",
    "        \n",
    "#     def start_requests(self):\n",
    "#         urls = self.start_urls                            # 키워드 설정은 됐으나 컬럼명에 맞지 않는 row데이터 삽입됨\n",
    "#         for url in urls:\n",
    "#             yield scrapy.Request(url, callback=self.parse)\n",
    "        \n",
    "#     def parse(self, response):\n",
    "#         item = CovidKeywordItem() \n",
    "#         item['vaccine'] = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         item['infection'] = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         item['soc_distance'] = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         item['support'] = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         item['vaccine'] = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['infection'] = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['soc_distance'] = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['support'] = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract() \n",
    "#         yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_keyword/covid_keyword/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile covid_keyword/covid_keyword/spiders/spider.py\n",
    "\n",
    "# import scrapy\n",
    "# from covid_keyword.items import CovidKeywordItem\n",
    "\n",
    "# class CovidSpider(scrapy.Spider):\n",
    "#     name = \"CovidKeyword\"\n",
    "#     allow_domain = ['https://www.naver.com/']\n",
    "#     start_urls = [\"https://search.naver.com/search.naver?where=news&query=&pd=4\"]\n",
    "    \n",
    "#     def __init__(self, keyword='백신', **kwargs):\n",
    "#         self.start_url = f\"https://search.naver.com/search.naver?where=news&query=코로나%20{keyword}&pd=4&ds=&de=\"\n",
    "#         super().__init__(**kwargs)\n",
    "        \n",
    "#     def start_requests(self):\n",
    "#         url = self.start_url\n",
    "#         yield scrapy.Request(url, callback=self.parse)\n",
    "        \n",
    "#     def parse(self, response):\n",
    "#         item = CovidKeywordItem() \n",
    "#         titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['pair'] = [pair for pair in zip(titles, links)]\n",
    "#         yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### start_urls 설정(방법2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_keyword/covid_keyword/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile covid_keyword/covid_keyword/spiders/spider.py\n",
    "\n",
    "# import scrapy\n",
    "# from covid_keyword.items import CovidKeywordItem\n",
    "\n",
    "# class CovidSpider(scrapy.Spider):\n",
    "#     name = \"CovidKeyword\"\n",
    "#     allow_domain = ['https://www.naver.com/']\n",
    "#     start_urls = [\"https://search.naver.com/search.naver?where=news&query=코로나%20수도권%20확진&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20국내%20백신&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20사회적거리두기&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20정부%20재난지원금&pd=4\",\n",
    "#                  ]\n",
    "       \n",
    "#     def start_requests(self):\n",
    "#         urls = self.start_urls\n",
    "#         for url in urls:\n",
    "#             yield scrapy.Request(url, callback=self.parse)\n",
    "    \n",
    "#     def parse(self, response):\n",
    "#         item = CovidKeywordItem()\n",
    "#         titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['pair'] = [pair for pair in zip(titles, links)]\n",
    "        \n",
    "#         yield item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_keyword/covid_keyword/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile covid_keyword/covid_keyword/spiders/spider.py\n",
    "\n",
    "# import scrapy\n",
    "# from covid_keyword.items import CovidKeywordItem\n",
    "\n",
    "# class CovidSpider(scrapy.Spider):\n",
    "#     name = \"CovidKeyword\"\n",
    "#     allow_domain = ['https://www.naver.com/']\n",
    "#     start_urls = [\"https://search.naver.com/search.naver?where=news&query=코로나%20수도권%20확진&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20국내%20백신&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20사회적거리두기&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20정부%20재난지원금&pd=4\",\n",
    "#                  ]\n",
    "       \n",
    "#     def start_requests(self):\n",
    "#         urls = self.start_urls\n",
    "#         for url in urls:\n",
    "#             yield scrapy.Request(url, callback=self.parse)\n",
    "    \n",
    "#     def parse(self, response):\n",
    "#         item = CovidKeywordItem()\n",
    "#         item['titles'] = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         item['links'] = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_keyword/covid_keyword/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile covid_keyword/covid_keyword/spiders/spider.py\n",
    "\n",
    "# import scrapy\n",
    "# from covid_keyword.items import CovidKeywordItem\n",
    "\n",
    "# class CovidSpider(scrapy.Spider):\n",
    "#     name = \"CovidKeyword\"\n",
    "#     allow_domain = ['https://www.naver.com/']\n",
    "#     start_urls = [\"https://search.naver.com/search.naver?where=news&query=코로나%20확진&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20백신&pd=4\",\n",
    "#                   \"https://search.naver.com/search.naver?where=news&query=코로나%20사회적거리두기&pd=4\",\n",
    "#                  ]\n",
    "       \n",
    "#     def start_requests(self):\n",
    "#         url = self.start_urls\n",
    "#         yield scrapy.Request(url, callback=self.parse)\n",
    "    \n",
    "#     def parse(self, response):\n",
    "#         item = CovidKeywordItem()\n",
    "#         titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "#         links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "#         item['pair'] = [pair for pair in zip(titles, links)]\n",
    "#         yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "# %%writefile run.sh\n",
    "# cd covid_keyword\n",
    "# scrapy crawl CovidKeyword -o covid_keyword.csv -a kword1='국내' -a kword2='백신'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "cd covid_keyword\n",
    "scrapy crawl CovidKeyword -o covid_keyword.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/ROBOTSTXT_OBEY = True/ROBOTSTXT_OBEY = False/' covid_keyword/covid_keyword/settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-05 20:58:24 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: covid_keyword)\n",
      "2021-03-05 20:58:24 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Dec 28 2020, 03:27:25) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-5.4.0-1037-aws-x86_64-with-debian-buster-sid\n",
      "2021-03-05 20:58:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-03-05 20:58:24 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'covid_keyword',\n",
      " 'NEWSPIDER_MODULE': 'covid_keyword.spiders',\n",
      " 'SPIDER_MODULES': ['covid_keyword.spiders']}\n",
      "2021-03-05 20:58:24 [scrapy.extensions.telnet] INFO: Telnet Password: 6da4c3f6220fa75e\n",
      "2021-03-05 20:58:24 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-03-05 20:58:24 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-03-05 20:58:24 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-03-05 20:58:24 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-03-05 20:58:24 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-03-05 20:58:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-03-05 20:58:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-03-05 20:58:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EA%B5%AD%EB%82%B4%20%EB%B0%B1%EC%8B%A0&pd=4> (referer: None)\n",
      "2021-03-05 20:58:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%82%AC%ED%9A%8C%EC%A0%81%EA%B1%B0%EB%A6%AC%EB%91%90%EA%B8%B0&pd=4> (referer: None)\n",
      "2021-03-05 20:58:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%88%98%EB%8F%84%EA%B6%8C%20%ED%99%95%EC%A7%84&pd=4> (referer: None)\n",
      "2021-03-05 20:58:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%A0%95%EB%B6%80%20%EC%9E%AC%EB%82%9C%EC%A7%80%EC%9B%90%EA%B8%88&pd=4> (referer: None)\n",
      "2021-03-05 20:58:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EA%B5%AD%EB%82%B4%20%EB%B0%B1%EC%8B%A0&pd=4>\n",
      "{'vaccine': [(\"화이자 백신 만16세 이상 대상 허가…'초저온' 보관조건은 유지(종합)\",\n",
      "              'http://yna.kr/AKR20210305087551017?did=1195m'),\n",
      "             ('화이자 백신, 국내 두 번째 허가…\"16세 이상 접종 가능\"',\n",
      "              'https://news.joins.com/article/olink/23600227'),\n",
      "             (\"코로나19 백신 접종자 22만명 넘어…'접종 후 사망' 총 6명(상보)\",\n",
      "              'https://view.asiae.co.kr/article/2021030510025814592')]}\n",
      "2021-03-05 20:58:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%82%AC%ED%9A%8C%EC%A0%81%EA%B1%B0%EB%A6%AC%EB%91%90%EA%B8%B0&pd=4>\n",
      "{'soc_distance': [('거리두기 5→4단계…3~9인 모임금지, 집합금지 최소화(종합)',\n",
      "                   'http://www.newsis.com/view/?id=NISX20210305_0001360824&cID=10201&pID=10200'),\n",
      "                  ('거리두기 4단계로…영업금지 풀고 사모임 금지 3~9인이상 세분화',\n",
      "                   'http://yna.kr/AKR20210305052100530?did=1195m'),\n",
      "                  ('거리두기 4단계로 개편… 사모임 금지 3~9인 이상 세분화',\n",
      "                   'https://health.chosun.com/site/data/html_dir/2021/03/05/2021030502416.html')]}\n",
      "2021-03-05 20:58:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%88%98%EB%8F%84%EA%B6%8C%20%ED%99%95%EC%A7%84&pd=4>\n",
      "{'infection': [('서울 신규확진 104명…음식점·병원·사우나 감염 확산(종합)',\n",
      "                'http://www.newsis.com/view/?id=NISX20210305_0001360425&cID=10801&pID=14000'),\n",
      "               ('코로나19 신규 확진 398명…경기 168명·서울 129명 등',\n",
      "                'http://news.kbs.co.kr/news/view.do?ncd=5132001&ref=A'),\n",
      "               (\"코로나19 백신 접종자 22만명 넘어…'접종 후 사망' 총 6명(상보)\",\n",
      "                'https://view.asiae.co.kr/article/2021030510025814592')]}\n",
      "2021-03-05 20:58:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%A0%95%EB%B6%80%20%EC%9E%AC%EB%82%9C%EC%A7%80%EC%9B%90%EA%B8%88&pd=4>\n",
      "{'support': [('정 총리 \"4차 재난지원금, \\'민생 치료제\\'이자 \\'민생 백신\\'\"',\n",
      "              'https://hankookilbo.com/News/Read/A2021030509410002621?did=NA'),\n",
      "             ('역대급 4차 재난지원금, 추가 지원금 논의 또 필요하다고요?',\n",
      "              'https://www.ytn.co.kr/_ln/0101_202103051316311713'),\n",
      "             ('野 \"정부 무책임·주먹구구 추경…노점상 지원 따져볼 것\"',\n",
      "              'http://www.newsis.com/view/?id=NISX20210305_0001360057&cID=10301&pID=10300')]}\n",
      "2021-03-05 20:58:25 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2021-03-05 20:58:25 [scrapy.extensions.feedexport] INFO: Stored csv feed (4 items) in: covid_keyword.csv\n",
      "2021-03-05 20:58:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 1340,\n",
      " 'downloader/request_count': 4,\n",
      " 'downloader/request_method_count/GET': 4,\n",
      " 'downloader/response_bytes': 432618,\n",
      " 'downloader/response_count': 4,\n",
      " 'downloader/response_status_count/200': 4,\n",
      " 'elapsed_time_seconds': 0.594679,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2021, 3, 5, 11, 58, 25, 432155),\n",
      " 'item_scraped_count': 4,\n",
      " 'log_count/DEBUG': 8,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 55668736,\n",
      " 'memusage/startup': 55668736,\n",
      " 'response_received_count': 4,\n",
      " 'scheduler/dequeued': 4,\n",
      " 'scheduler/dequeued/memory': 4,\n",
      " 'scheduler/enqueued': 4,\n",
      " 'scheduler/enqueued/memory': 4,\n",
      " 'start_time': datetime.datetime(2021, 3, 5, 11, 58, 24, 837476)}\n",
      "2021-03-05 20:58:25 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infection</th>\n",
       "      <th>soc_distance</th>\n",
       "      <th>support</th>\n",
       "      <th>vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(\"화이자 백신 만16세 이상 대상 허가…'초저온' 보관조건은 유지(종합)\", '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[('거리두기 5→4단계…3~9인 모임금지, 집합금지 최소화(종합)', 'http:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[('서울 신규확진 104명…음식점·병원·사우나 감염 확산(종합)', 'http:/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[('정 총리 \"4차 재난지원금, \\'민생 치료제\\'이자 \\'민생 백신\\'\"', '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           infection  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  [('서울 신규확진 104명…음식점·병원·사우나 감염 확산(종합)', 'http:/...   \n",
       "3                                                NaN   \n",
       "\n",
       "                                        soc_distance  \\\n",
       "0                                                NaN   \n",
       "1  [('거리두기 5→4단계…3~9인 모임금지, 집합금지 최소화(종합)', 'http:...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "\n",
       "                                             support  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  [('정 총리 \"4차 재난지원금, \\'민생 치료제\\'이자 \\'민생 백신\\'\"', '...   \n",
       "\n",
       "                                             vaccine  \n",
       "0  [(\"화이자 백신 만16세 이상 대상 허가…'초저온' 보관조건은 유지(종합)\", '...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./covid_keyword/covid_keyword.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[(\\'서울 신규확진 104명…음식점·병원·사우나 감염 확산(종합)\\', \\'http://www.newsis.com/view/?id=NISX20210305_0001360425&cID=10801&pID=14000\\'), (\\'코로나19 신규 확진 398명…경기 168명·서울 129명 등\\', \\'http://news.kbs.co.kr/news/view.do?ncd=5132001&ref=A\\'), (\"코로나19 백신 접종자 22만명 넘어…\\'접종 후 사망\\' 총 6명(상보)\", \\'https://view.asiae.co.kr/article/2021030510025814592\\')]',\n",
       " \"[('거리두기 5→4단계…3~9인 모임금지, 집합금지 최소화(종합)', 'http://www.newsis.com/view/?id=NISX20210305_0001360824&cID=10201&pID=10200'), ('거리두기 4단계로…영업금지 풀고 사모임 금지 3~9인이상 세분화', 'http://yna.kr/AKR20210305052100530?did=1195m'), ('거리두기 4단계로 개편… 사모임 금지 3~9인 이상 세분화', 'https://health.chosun.com/site/data/html_dir/2021/03/05/2021030502416.html')]\",\n",
       " '[(\\'정 총리 \"4차 재난지원금, \\\\\\'민생 치료제\\\\\\'이자 \\\\\\'민생 백신\\\\\\'\"\\', \\'https://hankookilbo.com/News/Read/A2021030509410002621?did=NA\\'), (\\'역대급 4차 재난지원금, 추가 지원금 논의 또 필요하다고요?\\', \\'https://www.ytn.co.kr/_ln/0101_202103051316311713\\'), (\\'野 \"정부 무책임·주먹구구 추경…노점상 지원 따져볼 것\"\\', \\'http://www.newsis.com/view/?id=NISX20210305_0001360057&cID=10301&pID=10300\\')]',\n",
       " '[(\"화이자 백신 만16세 이상 대상 허가…\\'초저온\\' 보관조건은 유지(종합)\", \\'http://yna.kr/AKR20210305087551017?did=1195m\\'), (\\'화이자 백신, 국내 두 번째 허가…\"16세 이상 접종 가능\"\\', \\'https://news.joins.com/article/olink/23600227\\'), (\"코로나19 백신 접종자 22만명 넘어…\\'접종 후 사망\\' 총 6명(상보)\", \\'https://view.asiae.co.kr/article/2021030510025814592\\')]')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['infection'][2], df['soc_distance'][1], df['support'][3], df['vaccine'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://15.164.101.134:27017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('60461811131da53a021e4f84')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client.kword_rudan\n",
    "collection = db.title\n",
    "collection.insert({\"title\":\"scrapy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_keyword/covid_keyword/mongodb.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_keyword/covid_keyword/mongodb.py\n",
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://15.164.101.134:27017\")\n",
    "db = client.covid_title_kword\n",
    "collection = db.title_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_keyword/covid_keyword/pipelines.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_keyword/covid_keyword/pipelines.py\n",
    "from itemadapter import ItemAdapter\n",
    "from .mongodb import collection\n",
    "\n",
    "class CovidKeywordPipeline:\n",
    "    def process_item(self, item, spider):\n",
    "        form = {\"vaccine\": item[\"vaccine\"],\n",
    "                \"infection\": item[\"infection\"],\n",
    "                \"soc_distance\": item[\"soc_distance\"],\n",
    "                \"support\": item[\"support\"],\n",
    "               }\n",
    "        collection.insert(form)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-08 21:46:02 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: covid_keyword)\n",
      "2021-03-08 21:46:02 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Dec 28 2020, 03:27:25) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-5.4.0-1038-aws-x86_64-with-debian-buster-sid\n",
      "2021-03-08 21:46:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-03-08 21:46:02 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'covid_keyword',\n",
      " 'NEWSPIDER_MODULE': 'covid_keyword.spiders',\n",
      " 'SPIDER_MODULES': ['covid_keyword.spiders']}\n",
      "2021-03-08 21:46:02 [scrapy.extensions.telnet] INFO: Telnet Password: b7ae6d3194cad5f4\n",
      "2021-03-08 21:46:02 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-03-08 21:46:02 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-03-08 21:46:02 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-03-08 21:46:02 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-03-08 21:46:02 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-03-08 21:46:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-03-08 21:46:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-03-08 21:46:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%82%AC%ED%9A%8C%EC%A0%81%EA%B1%B0%EB%A6%AC%EB%91%90%EA%B8%B0&pd=4> (referer: None)\n",
      "2021-03-08 21:46:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%A0%95%EB%B6%80%20%EC%A7%80%EC%9B%90%EA%B8%88&pd=4> (referer: None)\n",
      "2021-03-08 21:46:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EA%B5%AD%EB%82%B4%20%EB%B0%B1%EC%8B%A0&pd=4> (referer: None)\n",
      "2021-03-08 21:46:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%88%98%EB%8F%84%EA%B6%8C%20%ED%99%95%EC%A7%84&pd=4> (referer: None)\n",
      "2021-03-08 21:46:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%82%AC%ED%9A%8C%EC%A0%81%EA%B1%B0%EB%A6%AC%EB%91%90%EA%B8%B0&pd=4>\n",
      "{'soc_distance': [('정부, \"14일 이후 거리두기 조정안 12일 발표\"',\n",
      "                   'http://www.wowtv.co.kr/NewsCenter/News/Read?articleId=A202103080187&t=NN'),\n",
      "                  ('정부 \"내주 적용할 거리두기 조정안 이번주 금요일 발표 목표\"(종합)',\n",
      "                   'http://yna.kr/AKR20210308066651530?did=1195m'),\n",
      "                  ('거리두기 개편‥등교 확대 기대감 늘어',\n",
      "                   'http://news.ebs.co.kr/ebsnews/allView/20466256/N'),\n",
      "                  ('정부 \"내주 적용할 거리두기 조정안 이번주 금요일 발표 목표\"',\n",
      "                   'https://imnews.imbc.com/news/2021/society/article/6112155_34873.html'),\n",
      "                  ('곳곳에 열린 행사장 가보니 \"느슨해진 거리두기\"',\n",
      "                   'https://news.kjmbc.co.kr/node/324304'),\n",
      "                  ('\\'백신 접종 후 감염\\' 3건··· \"거리두기·마스크 더 잘 지켜야\"',\n",
      "                   'http://news.khan.co.kr/kh_news/khan_art_view.html?artid=202103081744001&code=940601'),\n",
      "                  ('코로나19 이슈 - 사회적 거리두기 개편안 초안, 내용은?',\n",
      "                   'http://www.cts.tv/news/view?ncate=THMNWS01&dpid=274629'),\n",
      "                  (\"근무여건상 거리두기 불가능…'60명 집단감염'도축장 방역 사각지대\",\n",
      "                   'https://www.news1.kr/articles/?4234060'),\n",
      "                  ('기모란 \"새 거리두기안, 확진자 지금의 절반으로 내려야 적용\"',\n",
      "                   'https://hankookilbo.com/News/Read/A2021030811560001496?did=NA'),\n",
      "                  ('\"분란만 커졌네요\"…거리두기 개편에도 자영업자들 한숨만',\n",
      "                   'http://www.newspim.com/news/view/20210308000764')]}\n",
      "2021-03-08 21:46:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%A0%95%EB%B6%80%20%EC%A7%80%EC%9B%90%EA%B8%88&pd=4>\n",
      "{'support': [('\"재난지원금 안 주면 버스 몰고 한강 간다\"…전세버스 기사들 절규',\n",
      "              'http://www.edaily.co.kr/news/newspath.asp?newsid=03949126628981352'),\n",
      "             ('장수군의회 \"4차 재난지원금에 농업인 포함되어야\"',\n",
      "              'https://www.news1.kr/articles/?4233882'),\n",
      "             ('박남춘 시장 “4차 재난지원금 신속 지급, 자체 추가지원 검토” 주문',\n",
      "              'http://www.fnnews.com/news/202103081507151939'),\n",
      "             ('경북도의회 \"농어업 분야에도 재난지원금을\"',\n",
      "              'http://yna.kr/AKR20210308104200053?did=1195m'),\n",
      "             ('괴산군의회 \"4차 재난지원금에 농민도 포함시켜야\"',\n",
      "              'http://www.newsis.com/view/?id=NISX20210308_0001362516&cID=10806&pID=10800'),\n",
      "             ('장수군의회 \"정부 제4차 재난지원금 농업인 포함을\"',\n",
      "              'http://www.jjan.kr/news/articleView.html?idxno=2103725'),\n",
      "             ('코로나19 일자리 위기 1년…“20대 여성 4명 중 1명 퇴직 경험”',\n",
      "              'http://www.hani.co.kr/arti/society/women/985842.html'),\n",
      "             ('강원도의회 \"정부 4차 재난지원금 농어업인 포함 촉구\"',\n",
      "              'http://www.m-i.kr/news/articleView.html?idxno=804393'),\n",
      "             ('갈등만 키운 \\'노점상 재난지원금\\'…\"탁상행정\"',\n",
      "              'http://www.edaily.co.kr/news/newspath.asp?newsid=03991766628981352'),\n",
      "             ('돌봄 종사자 지원금 사업 집행률 0.1%…왜?',\n",
      "              'http://news.khan.co.kr/kh_news/khan_art_view.html?artid=202103081418001&code=920100')]}\n",
      "2021-03-08 21:46:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EA%B5%AD%EB%82%B4%20%EB%B0%B1%EC%8B%A0&pd=4>\n",
      "{'vaccine': [('당국 \"코로나19 백신 접종후 감염 사례 총 3명…전체 규모 조사\"(종합)',\n",
      "              'http://yna.kr/AKR20210308108951530?did=1195m'),\n",
      "             ('정부 \"백신접종 후 사망 8건 인과성 없다\" 잠정결론 [종합]',\n",
      "              'https://www.hankyung.com/society/article/2021030887327'),\n",
      "             ('AZ 백신 고령층 접종 곧 결론… 접종자 중 3명 확진',\n",
      "              'http://news.kmib.co.kr/article/view.asp?arcid=0015609625&code=61121111&cp=nv'),\n",
      "             ('접종 뒤 사망 8명 백신과 무관…\"AZ백신 신뢰 높아질 것\"',\n",
      "              'http://news.tf.co.kr/read/life/1846894.htm'),\n",
      "             ('백신 열흘간 31만명 접종···우선 대상자 41% 완료',\n",
      "              'https://www.sedaily.com/NewsView/22JQ8VJDES'),\n",
      "             ('\"국내 코로나19 백신 접종 후 사망, 인과성 없어\"',\n",
      "              'https://zdnet.co.kr/view/?no=20210308165444'),\n",
      "             ('[속보] \"백신 접종 후 사망 8명, 인과성 없다… 4명은 부검진행\"',\n",
      "              'http://www.busan.com/view/busan/view.php?code=2021030814254513588'),\n",
      "             ('“백신 접종 뒤 사망, 접종과 인과성 인정 어려워…감소세 정체 상황”',\n",
      "              'http://news.kbs.co.kr/news/view.do?ncd=5133716&ref=A'),\n",
      "             (\"'백신 무력화' 남아공 변이도 국내에 퍼졌나? 일가족 4명 중 3명 변이 확인\",\n",
      "              'https://news.jtbc.joins.com/article/article.aspx?news_id=NB11995430'),\n",
      "             ('\\'백신 접종 후 감염\\' 3건··· \"거리두기·마스크 더 잘 지켜야\"',\n",
      "              'http://news.khan.co.kr/kh_news/khan_art_view.html?artid=202103081744001&code=940601')]}\n",
      "2021-03-08 21:46:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%88%98%EB%8F%84%EA%B6%8C%20%ED%99%95%EC%A7%84&pd=4>\n",
      "{'infection': [('신규확진 346명, 휴일영향 사흘만에 400명 아래…산발감염 지속(종합)',\n",
      "                'http://yna.kr/AKR20210308027651530?did=1195m'),\n",
      "               ('코로나19 어제 346명 신규확진…사흘 만에 300명대',\n",
      "                'http://www.busan.com/view/busan/view.php?code=2021030809334752741'),\n",
      "               ('신규 확진 346명…오늘 백신 피해 조사 발표',\n",
      "                'https://imnews.imbc.com/replay/2021/nw1200/article/6112052_34908.html'),\n",
      "               ('대구서 동창모임·체육시설 관련 등 확진 6명 추가(종합)',\n",
      "                'http://yna.kr/AKR20210308019851053?did=1195m'),\n",
      "               ('\"거리두기 체계 바꾸려면 수도권 확진 200명보다 적어야\"',\n",
      "                'https://www.nocutnews.co.kr/news/5511852'),\n",
      "               ('코로나19 신규확진 346명…사흘 만에 다시 300명대',\n",
      "                'https://www.donga.com/news/article/all/20210308/105766715/1'),\n",
      "               ('코로나19, 8일 오후 6시까지 334명 확진',\n",
      "                'http://sports.khan.co.kr/news/sk_index.html?art_id=202103081908003&sec_id=560101&pt=nv'),\n",
      "               ('코로나19 오후 6시 확진자 334명…어제보다 84명 늘어',\n",
      "                'https://view.asiae.co.kr/article/2021030819561347464'),\n",
      "               ('중대본 \"수도권 확진 상황 심각\"…접종-사망 인과성 여부 오늘 발표',\n",
      "                'http://www.newsis.com/view/?id=NISX20210308_0001362031&cID=10201&pID=10200'),\n",
      "               ('신규확진 346명, 전일비 70명↓…사흘만에 300명대(상보)',\n",
      "                'https://www.news1.kr/articles/?4233303')]}\n",
      "2021-03-08 21:46:03 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2021-03-08 21:46:03 [scrapy.extensions.feedexport] INFO: Stored csv feed (4 items) in: covid_keyword.csv\n",
      "2021-03-08 21:46:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 1322,\n",
      " 'downloader/request_count': 4,\n",
      " 'downloader/request_method_count/GET': 4,\n",
      " 'downloader/response_bytes': 434122,\n",
      " 'downloader/response_count': 4,\n",
      " 'downloader/response_status_count/200': 4,\n",
      " 'elapsed_time_seconds': 0.710745,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2021, 3, 8, 12, 46, 3, 282181),\n",
      " 'item_scraped_count': 4,\n",
      " 'log_count/DEBUG': 8,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 55799808,\n",
      " 'memusage/startup': 55799808,\n",
      " 'response_received_count': 4,\n",
      " 'scheduler/dequeued': 4,\n",
      " 'scheduler/dequeued/memory': 4,\n",
      " 'scheduler/enqueued': 4,\n",
      " 'scheduler/enqueued/memory': 4,\n",
      " 'start_time': datetime.datetime(2021, 3, 8, 12, 46, 2, 571436)}\n",
      "2021-03-08 21:46:03 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
