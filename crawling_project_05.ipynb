{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 키워드별 Scrapy 프로젝트 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 키워드 '백신' 프로젝트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf covid_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'covid_vaccine', using template directory '/home/ubuntu/.pyenv/versions/3.6.9/envs/python3/lib/python3.6/site-packages/scrapy/templates/project', created in:\r\n",
      "    /home/ubuntu/python3/project/covid_vaccine\r\n",
      "\r\n",
      "You can start your first spider with:\r\n",
      "    cd covid_vaccine\r\n",
      "    scrapy genspider example example.com\r\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject covid_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mcovid_vaccine\u001b[00m\r\n",
      "├── \u001b[01;34mcovid_vaccine\u001b[00m\r\n",
      "│   ├── __init__.py\r\n",
      "│   ├── items.py\r\n",
      "│   ├── middlewares.py\r\n",
      "│   ├── pipelines.py\r\n",
      "│   ├── settings.py\r\n",
      "│   └── \u001b[01;34mspiders\u001b[00m\r\n",
      "│       └── __init__.py\r\n",
      "└── scrapy.cfg\r\n",
      "\r\n",
      "2 directories, 7 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree covid_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_vaccine/covid_vaccine/items.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_vaccine/covid_vaccine/items.py\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class CovidVaccineItem(scrapy.Item):\n",
    "    vaccine = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_vaccine/covid_vaccine/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_vaccine/covid_vaccine/spiders/spider.py\n",
    "\n",
    "import scrapy\n",
    "from covid_vaccine.items import CovidVaccineItem\n",
    "\n",
    "class CovidSpider(scrapy.Spider):\n",
    "    name = 'CovidVaccine'\n",
    "    allow_domain = ['https://www.naver.com/']\n",
    "\n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(\"https://search.naver.com/search.naver?where=news&query=코로나%20국내%20백신&pd=4\", callback=self.parse_kword)\n",
    "            \n",
    "    def parse_kword(self, response):\n",
    "        item = CovidVaccineItem()\n",
    "        vaccine_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "        vaccine_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "        item['vaccine'] = [vaccine for vaccine in zip(vaccine_titles, vaccine_links)]\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "cd covid_vaccine\n",
    "scrapy crawl CovidVaccine -o covid_vaccine.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/ROBOTSTXT_OBEY = True/ROBOTSTXT_OBEY = False/' covid_vaccine/covid_vaccine/settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-11 19:50:23 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: covid_vaccine)\n",
      "2021-03-11 19:50:23 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Dec 28 2020, 03:27:25) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-5.4.0-1038-aws-x86_64-with-debian-buster-sid\n",
      "2021-03-11 19:50:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-03-11 19:50:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'covid_vaccine',\n",
      " 'NEWSPIDER_MODULE': 'covid_vaccine.spiders',\n",
      " 'SPIDER_MODULES': ['covid_vaccine.spiders']}\n",
      "2021-03-11 19:50:23 [scrapy.extensions.telnet] INFO: Telnet Password: dc8641c92a1f6853\n",
      "2021-03-11 19:50:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-03-11 19:50:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-03-11 19:50:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-03-11 19:50:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-03-11 19:50:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-03-11 19:50:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-03-11 19:50:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-03-11 19:50:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EA%B5%AD%EB%82%B4%20%EB%B0%B1%EC%8B%A0&pd=4> (referer: None)\n",
      "2021-03-11 19:50:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EA%B5%AD%EB%82%B4%20%EB%B0%B1%EC%8B%A0&pd=4>\n",
      "{'vaccine': [('보관온도 이탈로 사용중지 백신 총 770회분…7개 병원 관리 소홀',\n",
      "              'http://yna.kr/AKR20210311139300530?did=1195m'),\n",
      "             ('2회차 백신 풀어 접종자 늘릴까…\"화이자 어렵고, AZ는 해볼 만\"',\n",
      "              'https://www.news1.kr/articles/?4236842'),\n",
      "             ('65세 이상도 AZ 백신 맞는다(종합)',\n",
      "              'https://www.sedaily.com/NewsView/22JRLPREHN'),\n",
      "             ('SK바이오사이언스, 코로나19 변이 백신 개발 돌입…CEPI 지원',\n",
      "              'https://view.asiae.co.kr/article/2021031109045188427'),\n",
      "             ('신규 확진 465명...65세 이상도 AZ백신 접종',\n",
      "              'https://www.ytn.co.kr/_ln/0103_202103111157107530'),\n",
      "             (\"'65세 이상' AZ 백신 맞는다…접종 총 50만 명 넘어\",\n",
      "              'https://news.sbs.co.kr/news/endPage.do?news_id=N1006238363&plink=ORI&cooper=NAVER'),\n",
      "             ('백신 이상반응 1천73건 늘어 총 6천859건…추가 사망신고 없어',\n",
      "              'http://yna.kr/AKR20210311058900530?did=1195m'),\n",
      "             ('백신 이상반응 1073건 늘어 총 6859건',\n",
      "              'http://www.busan.com/view/busan/view.php?code=2021031110180133472'),\n",
      "             ('[속보] 백신 접종 50만명 넘어…이상반응 1073건 추가',\n",
      "              'http://news.kmib.co.kr/article/view.asp?arcid=0015619945&code=61121111&cp=nv'),\n",
      "             ('[단독] AZ 백신 5월 말 350만 명분 도입 확정',\n",
      "              'https://news.sbs.co.kr/news/endPage.do?news_id=N1006237468&plink=ORI&cooper=NAVER')]}\n",
      "2021-03-11 19:50:23 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2021-03-11 19:50:23 [scrapy.extensions.feedexport] INFO: Stored csv feed (1 items) in: covid_vaccine.csv\n",
      "2021-03-11 19:50:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 320,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 114578,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.425555,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2021, 3, 11, 10, 50, 23, 701645),\n",
      " 'item_scraped_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 56000512,\n",
      " 'memusage/startup': 56000512,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2021, 3, 11, 10, 50, 23, 276090)}\n",
      "2021-03-11 19:50:23 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('보관온도 이탈로 사용중지 백신 총 770회분…7개 병원 관리 소홀', 'htt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             vaccine\n",
       "0  [('보관온도 이탈로 사용중지 백신 총 770회분…7개 병원 관리 소홀', 'htt..."
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vaccine = pd.read_csv('./covid_vaccine/covid_vaccine.csv')\n",
    "df_vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(\\'보관온도 이탈로 사용중지 백신 총 770회분…7개 병원 관리 소홀\\', \\'http://yna.kr/AKR20210311139300530?did=1195m\\'), (\\'2회차 백신 풀어 접종자 늘릴까…\"화이자 어렵고, AZ는 해볼 만\"\\', \\'https://www.news1.kr/articles/?4236842\\'), (\\'65세 이상도 AZ 백신 맞는다(종합)\\', \\'https://www.sedaily.com/NewsView/22JRLPREHN\\'), (\\'SK바이오사이언스, 코로나19 변이 백신 개발 돌입…CEPI 지원\\', \\'https://view.asiae.co.kr/article/2021031109045188427\\'), (\\'신규 확진 465명...65세 이상도 AZ백신 접종\\', \\'https://www.ytn.co.kr/_ln/0103_202103111157107530\\'), (\"\\'65세 이상\\' AZ 백신 맞는다…접종 총 50만 명 넘어\", \\'https://news.sbs.co.kr/news/endPage.do?news_id=N1006238363&plink=ORI&cooper=NAVER\\'), (\\'백신 이상반응 1천73건 늘어 총 6천859건…추가 사망신고 없어\\', \\'http://yna.kr/AKR20210311058900530?did=1195m\\'), (\\'백신 이상반응 1073건 늘어 총 6859건\\', \\'http://www.busan.com/view/busan/view.php?code=2021031110180133472\\'), (\\'[속보] 백신 접종 50만명 넘어…이상반응 1073건 추가\\', \\'http://news.kmib.co.kr/article/view.asp?arcid=0015619945&code=61121111&cp=nv\\'), (\\'[단독] AZ 백신 5월 말 350만 명분 도입 확정\\', \\'https://news.sbs.co.kr/news/endPage.do?news_id=N1006237468&plink=ORI&cooper=NAVER\\')]'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vaccine['vaccine'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 키워드 '거리두기' 프로젝트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf covid_soc_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'covid_soc_distance', using template directory '/home/ubuntu/.pyenv/versions/3.6.9/envs/python3/lib/python3.6/site-packages/scrapy/templates/project', created in:\r\n",
      "    /home/ubuntu/python3/project/covid_soc_distance\r\n",
      "\r\n",
      "You can start your first spider with:\r\n",
      "    cd covid_soc_distance\r\n",
      "    scrapy genspider example example.com\r\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject covid_soc_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mcovid_soc_distance/\u001b[00m\r\n",
      "├── \u001b[01;34mcovid_soc_distance\u001b[00m\r\n",
      "│   ├── __init__.py\r\n",
      "│   ├── items.py\r\n",
      "│   ├── middlewares.py\r\n",
      "│   ├── pipelines.py\r\n",
      "│   ├── settings.py\r\n",
      "│   └── \u001b[01;34mspiders\u001b[00m\r\n",
      "│       └── __init__.py\r\n",
      "└── scrapy.cfg\r\n",
      "\r\n",
      "2 directories, 7 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree covid_soc_distance/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_soc_distance/covid_soc_distance/items.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_soc_distance/covid_soc_distance/items.py\n",
    "import scrapy\n",
    "\n",
    "class CovidSocDistanceItem(scrapy.Item):\n",
    "    soc_distance = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_soc_distance/covid_soc_distance/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_soc_distance/covid_soc_distance/spiders/spider.py\n",
    "\n",
    "import scrapy\n",
    "from covid_soc_distance.items import CovidSocDistanceItem\n",
    "\n",
    "class CovidSpider(scrapy.Spider):\n",
    "    name = 'CovidSocDistance'\n",
    "    allow_domain = ['https://www.naver.com/']\n",
    "    \n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(\"https://search.naver.com/search.naver?where=news&query=코로나%20사회적거리두기&pd=4\", callback=self.parse_kword)\n",
    "        \n",
    "    def parse_kword(self, response):\n",
    "        item = CovidSocDistanceItem()\n",
    "        soc_distance_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "        soc_distance_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "        item['soc_distance'] = [soc_distance for soc_distance in zip(soc_distance_titles, soc_distance_links)]\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "cd covid_soc_distance\n",
    "scrapy crawl CovidSocDistance -o covid_soc_distance.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/ROBOTSTXT_OBEY = True/ROBOTSTXT_OBEY = False/' covid_soc_distance/covid_soc_distance/settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-11 20:00:03 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: covid_soc_distance)\n",
      "2021-03-11 20:00:03 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Dec 28 2020, 03:27:25) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-5.4.0-1038-aws-x86_64-with-debian-buster-sid\n",
      "2021-03-11 20:00:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-03-11 20:00:03 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'covid_soc_distance',\n",
      " 'NEWSPIDER_MODULE': 'covid_soc_distance.spiders',\n",
      " 'SPIDER_MODULES': ['covid_soc_distance.spiders']}\n",
      "2021-03-11 20:00:03 [scrapy.extensions.telnet] INFO: Telnet Password: 30ff1409c6f9ce21\n",
      "2021-03-11 20:00:03 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-03-11 20:00:03 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-03-11 20:00:03 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-03-11 20:00:03 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-03-11 20:00:03 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-03-11 20:00:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-03-11 20:00:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-03-11 20:00:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%82%AC%ED%9A%8C%EC%A0%81%EA%B1%B0%EB%A6%AC%EB%91%90%EA%B8%B0&pd=4> (referer: None)\n",
      "2021-03-11 20:00:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%82%AC%ED%9A%8C%EC%A0%81%EA%B1%B0%EB%A6%AC%EB%91%90%EA%B8%B0&pd=4>\n",
      "{'soc_distance': [('일평균 지역발생 406명 2.5단계 범위,거리두기-5인금지 연장무게(종합)',\n",
      "                   'http://yna.kr/AKR20210310149551530?did=1195m'),\n",
      "                  ('신규확진 465명, 사흘째 400명대…내일 거리두기 조정안 발표(종합)',\n",
      "                   'http://yna.kr/AKR20210311035251530?did=1195m'),\n",
      "                  ('신규확진 465명, 사흘 연속 400명대…거리두기 2.5단계 수준',\n",
      "                   'http://www.newsis.com/view/?id=NISX20210311_0001366415&cID=10201&pID=10200'),\n",
      "                  ('확진자 연일 400명대… 내일 거리두기 재연장 가능성',\n",
      "                   'http://www.wowtv.co.kr/NewsCenter/News/Read?articleId=A202103110091&t=NN'),\n",
      "                  ('코로나19 어제 465명···12일 거리두기 조정안 발표',\n",
      "                   'https://www.sedaily.com/NewsView/22JRL6A3U3'),\n",
      "                  ('오늘도 4백 명대 중후반…거리두기 격상 기준 육박',\n",
      "                   'https://imnews.imbc.com/replay/2021/nwtoday/article/6115017_34943.html'),\n",
      "                  ('오늘도 400명대, 2.5단계 재진입…거리두기-5인금지 연장 가능성',\n",
      "                   'http://yna.kr/AKR20210310149500530?did=1195m'),\n",
      "                  ('내일 거리두기 조정안 발표.. 5인이상 모임금지 연장될듯',\n",
      "                   'http://www.fnnews.com/news/202103110657282307'),\n",
      "                  ('AZ백신 접종, 65세 이상으로 확대…내일 거리두기 조정안 발표',\n",
      "                   'https://biz.sbs.co.kr/article_hub/20000006987?division=NAVER'),\n",
      "                  ('증평군새마을회, 사회적 거리두기 캠페인 진행',\n",
      "                   'http://www.breaknews.com/791542')]}\n",
      "2021-03-11 20:00:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2021-03-11 20:00:04 [scrapy.extensions.feedexport] INFO: Stored csv feed (1 items) in: covid_soc_distance.csv\n",
      "2021-03-11 20:00:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 344,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 114038,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.378461,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2021, 3, 11, 11, 0, 4, 110540),\n",
      " 'item_scraped_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 56082432,\n",
      " 'memusage/startup': 56082432,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2021, 3, 11, 11, 0, 3, 732079)}\n",
      "2021-03-11 20:00:04 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soc_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('일평균 지역발생 406명 2.5단계 범위,거리두기-5인금지 연장무게(종합)',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        soc_distance\n",
       "0  [('일평균 지역발생 406명 2.5단계 범위,거리두기-5인금지 연장무게(종합)',..."
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_soc_distance = pd.read_csv('./covid_soc_distance/covid_soc_distance.csv')\n",
    "df_soc_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('일평균 지역발생 406명 2.5단계 범위,거리두기-5인금지 연장무게(종합)', 'http://yna.kr/AKR20210310149551530?did=1195m'), ('신규확진 465명, 사흘째 400명대…내일 거리두기 조정안 발표(종합)', 'http://yna.kr/AKR20210311035251530?did=1195m'), ('신규확진 465명, 사흘 연속 400명대…거리두기 2.5단계 수준', 'http://www.newsis.com/view/?id=NISX20210311_0001366415&cID=10201&pID=10200'), ('확진자 연일 400명대… 내일 거리두기 재연장 가능성', 'http://www.wowtv.co.kr/NewsCenter/News/Read?articleId=A202103110091&t=NN'), ('코로나19 어제 465명···12일 거리두기 조정안 발표', 'https://www.sedaily.com/NewsView/22JRL6A3U3'), ('오늘도 4백 명대 중후반…거리두기 격상 기준 육박', 'https://imnews.imbc.com/replay/2021/nwtoday/article/6115017_34943.html'), ('오늘도 400명대, 2.5단계 재진입…거리두기-5인금지 연장 가능성', 'http://yna.kr/AKR20210310149500530?did=1195m'), ('내일 거리두기 조정안 발표.. 5인이상 모임금지 연장될듯', 'http://www.fnnews.com/news/202103110657282307'), ('AZ백신 접종, 65세 이상으로 확대…내일 거리두기 조정안 발표', 'https://biz.sbs.co.kr/article_hub/20000006987?division=NAVER'), ('증평군새마을회, 사회적 거리두기 캠페인 진행', 'http://www.breaknews.com/791542')]\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_soc_distance['soc_distance'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 키워드 '확진' 프로젝트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf covid_infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'covid_infection', using template directory '/home/ubuntu/.pyenv/versions/3.6.9/envs/python3/lib/python3.6/site-packages/scrapy/templates/project', created in:\r\n",
      "    /home/ubuntu/python3/project/covid_infection\r\n",
      "\r\n",
      "You can start your first spider with:\r\n",
      "    cd covid_infection\r\n",
      "    scrapy genspider example example.com\r\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject covid_infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mcovid_infection/\u001b[00m\r\n",
      "├── \u001b[01;34mcovid_infection\u001b[00m\r\n",
      "│   ├── __init__.py\r\n",
      "│   ├── items.py\r\n",
      "│   ├── middlewares.py\r\n",
      "│   ├── pipelines.py\r\n",
      "│   ├── settings.py\r\n",
      "│   └── \u001b[01;34mspiders\u001b[00m\r\n",
      "│       └── __init__.py\r\n",
      "└── scrapy.cfg\r\n",
      "\r\n",
      "2 directories, 7 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree covid_infection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_infection/covid_infection/items.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_infection/covid_infection/items.py\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class CovidInfectionItem(scrapy.Item):\n",
    "    infection = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_infection/covid_infection/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_infection/covid_infection/spiders/spider.py\n",
    "\n",
    "import scrapy\n",
    "from covid_infection.items import CovidInfectionItem\n",
    "\n",
    "class CovidSpider(scrapy.Spider):\n",
    "    name = 'CovidInfection'\n",
    "    allow_domain = ['https://www.naver.com/']\n",
    "    \n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(\"https://search.naver.com/search.naver?where=news&query=코로나%20수도권%20확진&pd=4\", callback=self.parse_kword)\n",
    "        \n",
    "    def parse_kword(self, response):\n",
    "        item = CovidInfectionItem()\n",
    "        infection_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "        infection_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "        item['infection'] = [infection for infection in zip(infection_titles, infection_links)]\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "cd covid_infection\n",
    "scrapy crawl CovidInfection -o covid_infection.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/ROBOTSTXT_OBEY = True/ROBOTSTXT_OBEY = False/' covid_infection/covid_infection/settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-11 20:00:58 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: covid_infection)\n",
      "2021-03-11 20:00:58 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Dec 28 2020, 03:27:25) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-5.4.0-1038-aws-x86_64-with-debian-buster-sid\n",
      "2021-03-11 20:00:58 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-03-11 20:00:58 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'covid_infection',\n",
      " 'NEWSPIDER_MODULE': 'covid_infection.spiders',\n",
      " 'SPIDER_MODULES': ['covid_infection.spiders']}\n",
      "2021-03-11 20:00:58 [scrapy.extensions.telnet] INFO: Telnet Password: 64eec63c43fcc825\n",
      "2021-03-11 20:00:58 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-03-11 20:00:59 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-03-11 20:00:59 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-03-11 20:00:59 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-03-11 20:00:59 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-03-11 20:00:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-03-11 20:00:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-03-11 20:00:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%88%98%EB%8F%84%EA%B6%8C%20%ED%99%95%EC%A7%84&pd=4> (referer: None)\n",
      "2021-03-11 20:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%88%98%EB%8F%84%EA%B6%8C%20%ED%99%95%EC%A7%84&pd=4>\n",
      "{'infection': [('신규확진 465명, 사흘째 400명대…내일 거리두기 조정안 발표(종합)',\n",
      "                'http://yna.kr/AKR20210311035251530?did=1195m'),\n",
      "               ('신규확진 사흘째 400명대, 2.5단계 수준…내일 거리두기 조정(종합)',\n",
      "                'http://www.newsis.com/view/?id=NISX20210311_0001366419&cID=10201&pID=10200'),\n",
      "               ('진주에서 11명 코로나19 확진 등 경남도내 하루 14명 감염',\n",
      "                'http://www.busan.com/view/busan/view.php?code=2021031113390390264'),\n",
      "               ('코로나19 신규 확진 465명…백신 총 50만 635명 접종',\n",
      "                'https://news.sbs.co.kr/news/endPage.do?news_id=N1006237997&plink=ORI&cooper=NAVER'),\n",
      "               ('코로나19 신규 확진자 465명…사흘째 400명대',\n",
      "                'http://www.hani.co.kr/arti/society/health/986314.html'),\n",
      "               ('코로나 신규 확진 465명... 사흘 연속 400명대',\n",
      "                'https://hankookilbo.com/News/Read/A2021031109150005622?did=NA'),\n",
      "               ('서울 신규 확진자 138명...사망자 1명 늘어',\n",
      "                'http://www.fnnews.com/news/202103111036391741'),\n",
      "               ('코로나19 신규 확진 465명...65세 이상도 AZ백신 접종',\n",
      "                'https://www.ytn.co.kr/_ln/0103_202103110941582034'),\n",
      "               ('코로나19 신규확진 465명…백신 이상반응 1073건 추가',\n",
      "                'https://www.donga.com/news/article/all/20210311/105824873/1'),\n",
      "               ('코로나19 신규확진 465명, 2.5단계 거리두기 기준 진입',\n",
      "                'https://www.nocutnews.co.kr/news/5513992')]}\n",
      "2021-03-11 20:00:59 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2021-03-11 20:00:59 [scrapy.extensions.feedexport] INFO: Stored csv feed (1 items) in: covid_infection.csv\n",
      "2021-03-11 20:00:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 329,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 113209,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.410534,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2021, 3, 11, 11, 0, 59, 453833),\n",
      " 'item_scraped_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 55914496,\n",
      " 'memusage/startup': 55914496,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2021, 3, 11, 11, 0, 59, 43299)}\n",
      "2021-03-11 20:00:59 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('신규확진 465명, 사흘째 400명대…내일 거리두기 조정안 발표(종합)', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           infection\n",
       "0  [('신규확진 465명, 사흘째 400명대…내일 거리두기 조정안 발표(종합)', '..."
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_infection = pd.read_csv('./covid_infection/covid_infection.csv')\n",
    "df_infection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 키워드 '지원금' 프로젝트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf covid_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'covid_support', using template directory '/home/ubuntu/.pyenv/versions/3.6.9/envs/python3/lib/python3.6/site-packages/scrapy/templates/project', created in:\r\n",
      "    /home/ubuntu/python3/project/covid_support\r\n",
      "\r\n",
      "You can start your first spider with:\r\n",
      "    cd covid_support\r\n",
      "    scrapy genspider example example.com\r\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject covid_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mcovid_support\u001b[00m\r\n",
      "├── \u001b[01;34mcovid_support\u001b[00m\r\n",
      "│   ├── __init__.py\r\n",
      "│   ├── items.py\r\n",
      "│   ├── middlewares.py\r\n",
      "│   ├── pipelines.py\r\n",
      "│   ├── settings.py\r\n",
      "│   └── \u001b[01;34mspiders\u001b[00m\r\n",
      "│       └── __init__.py\r\n",
      "└── scrapy.cfg\r\n",
      "\r\n",
      "2 directories, 7 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree covid_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting covid_support/covid_support/items.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_support/covid_support/items.py\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class CovidSupportItem(scrapy.Item):\n",
    "    support = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing covid_support/covid_support/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile covid_support/covid_support/spiders/spider.py\n",
    "\n",
    "import scrapy\n",
    "from covid_support.items import CovidSupportItem\n",
    "\n",
    "class CovidSpider(scrapy.Spider):\n",
    "    name = 'CovidSupport'\n",
    "    allow_domain = ['https://www.naver.com/']\n",
    "    \n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(\"https://search.naver.com/search.naver?where=news&query=코로나%20정부%20지원금&pd=4\", callback=self.parse_kword)\n",
    "        \n",
    "    def parse_kword(self, response):\n",
    "        item = CovidSupportItem()\n",
    "        support_titles = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@title').extract()\n",
    "        support_links = response.xpath('//*[@id=\"main_pack\"]/section/div/div[3]/ul/li/div[1]/div/a/@href').extract()\n",
    "        item['support'] = [support for support in zip(support_titles, support_links)]\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "cd covid_support\n",
    "scrapy crawl CovidSupport -o covid_support.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/ROBOTSTXT_OBEY = True/ROBOTSTXT_OBEY = False/' covid_support/covid_support/settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-11 20:02:15 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: covid_support)\n",
      "2021-03-11 20:02:15 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.6.9 (default, Dec 28 2020, 03:27:25) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-5.4.0-1038-aws-x86_64-with-debian-buster-sid\n",
      "2021-03-11 20:02:15 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-03-11 20:02:15 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'BOT_NAME': 'covid_support',\n",
      " 'NEWSPIDER_MODULE': 'covid_support.spiders',\n",
      " 'SPIDER_MODULES': ['covid_support.spiders']}\n",
      "2021-03-11 20:02:15 [scrapy.extensions.telnet] INFO: Telnet Password: 51ade4e1d3644fa1\n",
      "2021-03-11 20:02:15 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2021-03-11 20:02:15 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2021-03-11 20:02:15 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2021-03-11 20:02:15 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2021-03-11 20:02:15 [scrapy.core.engine] INFO: Spider opened\n",
      "2021-03-11 20:02:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2021-03-11 20:02:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2021-03-11 20:02:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%A0%95%EB%B6%80%20%EC%A7%80%EC%9B%90%EA%B8%88&pd=4> (referer: None)\n",
      "2021-03-11 20:02:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://search.naver.com/search.naver?where=news&query=%EC%BD%94%EB%A1%9C%EB%82%98%20%EC%A0%95%EB%B6%80%20%EC%A7%80%EC%9B%90%EA%B8%88&pd=4>\n",
      "{'support': [('[단독]\"농어민도 가구당 100만원\"…與, \\'4차 지원금\\' 1.3조 증액 요구',\n",
      "              'http://news.mt.co.kr/mtview.php?no=2021031110357639348'),\n",
      "             ('전시·컨벤션 업계도 \"코로나19 손실 보상하라\"',\n",
      "              'http://www.fnnews.com/news/202103111706561644'),\n",
      "             ('[진천소식]군의회, 재난지원금 대상 농업인 포함 촉구 등',\n",
      "              'http://www.newsis.com/view/?id=NISX20210311_0001367700&cID=10806&pID=10800'),\n",
      "             ('국립암센터, 코로나19 중증환자 전담치료병동 개소',\n",
      "              'https://biz.chosun.com/site/data/html_dir/2021/03/11/2021031100847.html?utm_source=naver&utm_medium=original&utm_campaign=biz'),\n",
      "             ('[포토] 농업인 4차 재난지원금 지원 촉구',\n",
      "              'http://www.edaily.co.kr/news/newspath.asp?newsid=03598166628982336'),\n",
      "             ('주철현 \"장관들 뭐했냐\"…4차 재난지원금 농어업인 배제 질타',\n",
      "              'https://www.news1.kr/articles/?4238305'),\n",
      "             ('옥천군 농민단체 \"4차 재난지원금 농민에게도 지급하라\"',\n",
      "              'https://www.news1.kr/articles/?4237568'),\n",
      "             ('코로나로 인한 농·어민 피해 4700억원…재난지원금엔 반영 안 돼',\n",
      "              'http://news.heraldcorp.com/view.php?ud=20210311000650'),\n",
      "             ('전시·컨벤션·마이스·이벤트 업계 \"코로나 손실 보상하라\"',\n",
      "              'https://zdnet.co.kr/view/?no=20210311100525'),\n",
      "             ('국립암센터, 코로나19 중증 환자 전담치료병동 신설',\n",
      "              'http://www.docdocdoc.co.kr/news/articleView.html?idxno=2008539')]}\n",
      "2021-03-11 20:02:16 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2021-03-11 20:02:16 [scrapy.extensions.feedexport] INFO: Stored csv feed (1 items) in: covid_support.csv\n",
      "2021-03-11 20:02:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 329,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 114102,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.394173,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2021, 3, 11, 11, 2, 16, 4283),\n",
      " 'item_scraped_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 55652352,\n",
      " 'memusage/startup': 55652352,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2021, 3, 11, 11, 2, 15, 610110)}\n",
      "2021-03-11 20:02:16 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('[단독]\"농어민도 가구당 100만원\"…與, \\'4차 지원금\\' 1.3조 증액 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             support\n",
       "0  [('[단독]\"농어민도 가구당 100만원\"…與, \\'4차 지원금\\' 1.3조 증액 ..."
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_support = pd.read_csv('./covid_support/covid_support.csv')\n",
    "df_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(\\'[단독]\"농어민도 가구당 100만원\"…與, \\\\\\'4차 지원금\\\\\\' 1.3조 증액 요구\\', \\'http://news.mt.co.kr/mtview.php?no=2021031110357639348\\'), (\\'전시·컨벤션 업계도 \"코로나19 손실 보상하라\"\\', \\'http://www.fnnews.com/news/202103111706561644\\'), (\\'[진천소식]군의회, 재난지원금 대상 농업인 포함 촉구 등\\', \\'http://www.newsis.com/view/?id=NISX20210311_0001367700&cID=10806&pID=10800\\'), (\\'국립암센터, 코로나19 중증환자 전담치료병동 개소\\', \\'https://biz.chosun.com/site/data/html_dir/2021/03/11/2021031100847.html?utm_source=naver&utm_medium=original&utm_campaign=biz\\'), (\\'[포토] 농업인 4차 재난지원금 지원 촉구\\', \\'http://www.edaily.co.kr/news/newspath.asp?newsid=03598166628982336\\'), (\\'주철현 \"장관들 뭐했냐\"…4차 재난지원금 농어업인 배제 질타\\', \\'https://www.news1.kr/articles/?4238305\\'), (\\'옥천군 농민단체 \"4차 재난지원금 농민에게도 지급하라\"\\', \\'https://www.news1.kr/articles/?4237568\\'), (\\'코로나로 인한 농·어민 피해 4700억원…재난지원금엔 반영 안 돼\\', \\'http://news.heraldcorp.com/view.php?ud=20210311000650\\'), (\\'전시·컨벤션·마이스·이벤트 업계 \"코로나 손실 보상하라\"\\', \\'https://zdnet.co.kr/view/?no=20210311100525\\'), (\\'국립암센터, 코로나19 중증 환자 전담치료병동 신설\\', \\'http://www.docdocdoc.co.kr/news/articleView.html?idxno=2008539\\')]'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_support['support'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
